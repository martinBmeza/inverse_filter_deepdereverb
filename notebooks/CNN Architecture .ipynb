{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env SM_FRAMEWORK=tf.keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfkl\n",
    "#constantes\n",
    "RIR_PATH = '/home/mrtn/Documents/TESIS/de-reverb/bases de datos/data/impulsos'\n",
    "SPEECH_PATH = '/home/mrtn/Documents/TESIS/de-reverb/bases de datos/data/speech/train-clean-100'\n",
    "Q_e = 32\n",
    "LM = 5\n",
    "Pd = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_A = tfkl.Input((256, LM,1)) #DIMENSIONES K x L x C\n",
    "input_B = tfkl.Input((256, Pd,1))\n",
    "delay = tfkl.Reshape((256, 1, Pd))(input_B)\n",
    "\n",
    "encoder_0 = tfkl.Conv2D(16, kernel_size=(1,LM), strides=(2,1), name='Input_layer')(input_A)\n",
    "encoder_1 = tfkl.Conv2D(16, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_1')(encoder_0)\n",
    "encoder_2 = tfkl.Conv2D(32, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_2')(encoder_1)\n",
    "encoder_3 = tfkl.Conv2D(32, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_3')(encoder_2)\n",
    "encoder_4 = tfkl.Conv2D(64, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_4')(encoder_3)\n",
    "\n",
    "encoder_5 = tfkl.Conv2D(64, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_5')(encoder_4)\n",
    "\n",
    "decoder_6 = tfkl.Conv2DTranspose(64, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_6')(encoder_5)\n",
    "decoder_6 = tfkl.Add()([encoder_4, decoder_6])\n",
    "decoder_7 = tfkl.Conv2DTranspose(32, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_7')(decoder_6)\n",
    "decoder_7 = tfkl.Add()([encoder_3, decoder_7])\n",
    "decoder_8 = tfkl.Conv2DTranspose(32, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_8')(decoder_7)\n",
    "decoder_8 = tfkl.Add()([encoder_2, decoder_8])\n",
    "decoder_9 = tfkl.Conv2DTranspose(16, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_9')(decoder_8)\n",
    "decoder_9 = tfkl.Add()([encoder_1, decoder_9])\n",
    "decoder_10 = tfkl.Conv2DTranspose(16, kernel_size=(9,1), strides=(2,1), activation='relu',padding='same',name='hidden_10')(decoder_9)\n",
    "decoder_10 = tfkl.Add()([encoder_0, decoder_10])\n",
    "decoder_11 = tfkl.Conv2DTranspose(Pd, kernel_size=(9,1), strides=(2,1), activation='linear',padding='same',name='hidden_11')(decoder_10)\n",
    "\n",
    "out = tfkl.multiply([delay, decoder_11])\n",
    "out = tf.reduce_sum(out, 3)\n",
    "out = tfkl.Activation('relu')(out)\n",
    "\n",
    "ae = tf.keras.Model(inputs=[input_A, input_B], outputs=[out])\n",
    "\n",
    "ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 5, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_layer (Conv2D)            (None, 128, 1, 16)   96          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_1 (Conv2D)               (None, 64, 1, 16)    2320        Input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_2 (Conv2D)               (None, 32, 1, 32)    4640        hidden_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_3 (Conv2D)               (None, 16, 1, 32)    9248        hidden_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_4 (Conv2D)               (None, 8, 1, 64)     18496       hidden_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_5 (Conv2D)               (None, 4, 1, 64)     36928       hidden_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_6 (Conv2DTranspose)      (None, 8, 1, 64)     36928       hidden_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 1, 64)     0           hidden_4[0][0]                   \n",
      "                                                                 hidden_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_7 (Conv2DTranspose)      (None, 16, 1, 32)    18464       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 1, 32)    0           hidden_3[0][0]                   \n",
      "                                                                 hidden_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_8 (Conv2DTranspose)      (None, 32, 1, 32)    9248        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 1, 32)    0           hidden_2[0][0]                   \n",
      "                                                                 hidden_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_9 (Conv2DTranspose)      (None, 64, 1, 16)    4624        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 1, 16)    0           hidden_1[0][0]                   \n",
      "                                                                 hidden_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_10 (Conv2DTranspose)     (None, 128, 1, 16)   2320        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 256, 9, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 1, 16)   0           Input_layer[0][0]                \n",
      "                                                                 hidden_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 256, 1, 9)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_11 (Conv2DTranspose)     (None, 256, 1, 9)    1305        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 256, 1, 9)    0           reshape[0][0]                    \n",
      "                                                                 hidden_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 256, 1)]     0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 1)       0           tf_op_layer_Sum[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 144,617\n",
      "Trainable params: 144,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Alimentar con datos al bucle de entrenamiento\"\"\"\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, path='', batch_size=8, dim=(32767), n_channels=1,  shuffle=True):\n",
    "        'Initialization'\n",
    "        self.path = path\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        input_A = np.empty((self.batch_size, 257, 5))\n",
    "        input_B = np.empty((self.batch_size, 257, 9))\n",
    "        output = np.empty((self.batch_size, 257, 1))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            input_A, input_B, output = np.load(self.path + str(ID) + '.npy', allow_pickle = True)\n",
    "\n",
    "        return [input_A[:-1,:].reshape(1,256,5,1), input_B[:-1,:].reshape(1,256,9,1)], output[:-1].reshape(1,256,1)\n",
    "\n",
    "\n",
    "def build_generators(params):\n",
    "    \"\"\"\n",
    "    Crea instancias de la clase DataGenerator (para entrenamiento y valdiacion) a partir de un diccionario donde se determinan los parametros\n",
    "    del generador de datos, y el path principal.\n",
    "    PARAMETROS:\n",
    "        -MAIN_PATH (str) path principal de la carpeta de trabajo\n",
    "        -params (dict) diccionario con los campos 'dim'(int), 'batch_size'(int), 'shuffle'(bool) para configurar el generador de datos\n",
    "        -subpath (str) path de la carpeta dentro de data/ de donde tomar los datos. Por defecto esta asignada a 'data_ready' que es donde se encuentran\n",
    "        los datos procesados. Puede ser util cambiarla a la carpeta data_dummy para trabajar con los datos dummy en ocasiones de debuggeo\n",
    "    SALIDA:\n",
    "        -training_generator (DataGenerator) instancia de clase que contiene los datos para pasarse a una instancia de entrenamiento y proveer\n",
    "            los datos de entrenamiento al modelo\n",
    "        -validation_generator (DataGenerator) instancia de clase que contiene los datos para pasarse a una instancia de entrenamiento y proveer\n",
    "            los datos de validacion al modelo\n",
    "        \"\"\"\n",
    "\n",
    "    audio_list = glob.glob(params['path']+'/**/*.npy', recursive = True)\n",
    "\n",
    "    #seleccion random de sets\n",
    "    audio_numbers = list(range(0, len(audio_list)))\n",
    "    random.shuffle(audio_numbers)\n",
    "    train_n = int(len(audio_numbers)*0.9)\n",
    "    validation_n = len(audio_numbers) - train_n\n",
    "\n",
    "    partition = {'train' : audio_numbers[:train_n], 'validation' : audio_numbers[train_n:]}\n",
    "\n",
    "    # Generators\n",
    "    training_generator = DataGenerator(partition['train'], **params)\n",
    "    validation_generator = DataGenerator(partition['validation'], **params)\n",
    "\n",
    "    print('Cantidad de datos para entrenamiento:', len(partition['train']))\n",
    "    print('Cantidad de datos para validacion:', len(partition['validation']))\n",
    "    return training_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_a = []\n",
    "in_b = []\n",
    "out = []\n",
    "for i in range(1636):\n",
    "    input_A, input_B, output = np.load('npy_data/' + str(i) + '.npy', allow_pickle = True)\n",
    "    in_a.append(input_A[:-1,:].reshape(1,256,5,1))\n",
    "    in_b.append(input_B[:-1,:].reshape(1,256,9,1))\n",
    "    out.append(output[:-1].reshape(1,256,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos para entrenamiento: 1472\n",
      "Cantidad de datos para validacion: 164\n",
      "Epoch 1/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.6544\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.4613\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.4884\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.6109\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.6761\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.6607\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.5777\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.5904\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.4610\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.6244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4963e9b4f0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data generators\n",
    "params = {'path':'/home/mrtn/Documents/TESIS/de-reverb/nuevo_modelo/npy_data/', 'batch_size' : 16, 'dim' : (256, 256)}\n",
    "training_generator, validation_generator = build_generators(params)\n",
    "\n",
    "#cbks = [tf.keras.callbacks.EarlyStopping(monitor='loss',restore_best_weights=True, patience=2),\n",
    "#        tf.keras.callbacks.ModelCheckpoint('/home/martin/Documents/tesis/src/model/ckpts/weights.{epoch:02d}-{loss:.3f}.hdf5'),\n",
    "#        tf.keras.callbacks.TensorBoard(log_dir='tb_logs',profile_batch=0, update_freq='batch', histogram_freq=1)]\n",
    "\n",
    "#Entreno\n",
    "ae.fit(training_generator, epochs=10)\n",
    "#ae.fit(x = [in_b, in_a], y = out, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
